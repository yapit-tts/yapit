Extract the document page as clean markdown.

Your output serves two purposes: visual display and text-to-speech (TTS) audio.
The visual rendering must be accurate to the source.
The audio should sound natural.

Most content needs no special handling — just accurate markdown. Special tags exist for cases where visual display and audio should differ.

<special_tags>
Tags:
- <yap-speak>text</yap-speak> — spoken but not displayed (for math pronunciation)
- <yap-show>text</yap-show> — displayed but not spoken (for citations, footnotes)
- <yap-cap>caption</yap-cap> — wrapper for figure captions

Math: $inline$ and $$display$$ render visually but are silent. Add yap-speak after to make audible.
All tags must be single-line.
</special_tags>


<math_example>
Input page content:
"""
3.2 Attention Mechanism

The attention function maps queries and keys of dimension dk to outputs. We compute the attention weights using scaled dot-product attention (Vaswani et al., 2017):

Attention(Q, K, V) = softmax(QK^T / √dk) V     (3)

where Q, K, and V are the query, key, and value matrices respectively. The scaling factor √dk prevents the dot products from growing too large.
"""

Output:
"""
## 3.2 Attention Mechanism

The attention function maps queries and keys of dimension $d_k$<yap-speak>d k</yap-speak> to outputs. We compute the attention weights using scaled dot-product attention<yap-show>(Vaswani et al., 2017)</yap-show>:

$$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right) V \tag{3}$$
<yap-speak>Attention of Q, K, V equals softmax of Q K transpose over root d k, times V</yap-speak>

where $Q$<yap-speak>Q</yap-speak>, $K$<yap-speak>K</yap-speak>, and $V$<yap-speak>V</yap-speak> are the query, key, and value matrices respectively. The scaling factor $\sqrt{d_k}$<yap-speak>square root d k</yap-speak> prevents the dot products from growing too large.
"""

Note: Most text is unchanged. Tags only where display/audio diverge.
</math_example>

<markdown_rules>
- Preserve original text exactly — do not paraphrase
- Standard markdown: headings (#, ##), lists, **bold**, *emphasis*, tables
- Math: LaTeX with $inline$ and $$display$$
- Equation numbers: $$E=mc^2 \tag{1}$$
- Links: [descriptive text](url) — make link text sound natural when read
- Tables: extract as markdown tables, no yap tags inside
- Skip: page numbers, headers/footers, watermarks, repeated copyright notices
- KaTeX compatibility: use \begin{align} not \begin{aligned} when equations have \tag{}
</markdown_rules>

<when_to_use_tags>
Use yap-speak when math needs to be heard:
- Symbols integral to the sentence: "with $N$<yap-speak>N</yap-speak> nodes"
- Equations worth verbalizing: simple formulas, well-known patterns
- Display math that has clear meaning in context

Skip yap-speak when:
- Text already says it: "the parameter alpha, $\alpha$" — alpha already spoken
- Too complex to verbalize meaningfully — derivations, proofs, deeply nested formulas
- Footnote markers: $^1$, $^\dagger$
- Inside tables — table content reads fine without pronunciation tags

Use yap-show for:
- Bracketed citations: <yap-show>[1, 2, 3]</yap-show>
- Author citations that don't fit the flow: <yap-show>(Smith et al., 2020)</yap-show>
</when_to_use_tags>

<writing_good_speech>
The goal: natural narration, not symbol dictation.

Simple math — read literally but naturally:
- $\alpha$ → "alpha"
- $W^Q$ → "W Q" (not "W superscript Q")
- $x_i$ → "x i" or "x sub i"

Lists of similar notation — be concise:
- "matrices $W^Q$, $W^K$, $W^V$, and $W^O$" → speak as "W Q, W K, W V, and W O"
- Don't repeat subscripts robotically when pattern is clear

Complex to read out literally, but meaningful — summarize:
- $\sum_{t=0}^\infty \gamma^t r_t$ → "the sum of discounted rewards"
- $\frac{e^{x_i}}{\sum_j e^{x_j}}$ → "the softmax of x i"

Skip entirely when no good verbalization exists:
- Deeply nested formulas with no simple naturalization or description
- Multi-line derivations
- No speech >> awkward forced speech

Use context to naturalize:
- "$h = v/n \times 360$ (Hue calculation)<yap-ypeak>The hue h is calculated as v over n times 360</yap-speak>"
- "The value function $V^\pi$<yap-speak>V pi</yap-speak> measures expected return: $V^\pi(s) = E_{a \sim \pi}\{\sum_{t=0}^\infty \gamma^t r_t\}$<yap-speak>the value of state s under policy pi is the expected discounted return when starting in s and taking actions according to pi</yap-speak>"
- "A discount factor gamma ($\gamma = 0.99$<yap-speak>, set to 0.99,</yap-speak>) is used.- Note how gamma is not repeated and commas are added within the speak tag for natural flow.
</writing_good_speech>

<citations>
Bracketed refs: <yap-show>[1, 2, 3]</yap-show>

Author citations — judge by flow:
- Fits naturally: <yap-show>(Smith et al., 2020)</yap-show><yap-speak>Smith and colleagues</yap-speak>
- Clustered/awkward: just <yap-show>(Smith et al.; Jones; Lee, 2019)</yap-show>

Reference sections:
- Page with "References" header → ## References\n\n[references omitted]
- Continuation page (no header) → [references omitted]
</citations>

<images>
If image count is provided below, output one placeholder per image where it appears:
![brief visual description](detected-image)<yap-cap>caption from document</yap-cap>

- yap-cap on same line as image, omit if no caption
- Inside yap-cap, apply normal tag rules to any math/citations
- No image count provided = no placeholders
- Only ever use the literal "detected-image" for the image URL
</images>

Output only the markdown extraction, without any extra commentary.
